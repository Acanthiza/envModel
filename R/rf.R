

  make_rf_quick <- function(x_df
                             , y_vec
                             , trees = 499
                             , cl_obj = NULL
                             , use_mtry
                             ) {

    rf_cores <- if(isTRUE(is.null(cl_obj))) 1 else length(cl_obj)

    `%dopar%` <- foreach::`%dopar%`

    foreach::foreach(ntree = rep(ceiling(trees/rf_cores), rf_cores)
            , .combine = randomForest::combine
            , .packages = c("randomForest")
            ) %dopar%
      randomForest::randomForest(x = x_df
                                 , y = y_vec
                                 , importance = TRUE
                                 , mtry = use_mtry
                                 , ntree = ntree
                                 )

  }

#' Iteratively add trees to random forest until predictions stabilise
#'
#' @param env_df Dataframe with `clust_col`, `site_col` and columns `env_names`
#' @param clust_col Character. Name of the columns with clusters.
#' @param context Character. Name of the columns defining the context.
#' @param env_names Character. Name of the environmental variables (e.g.
#' `names(stack_list)`).
#' @param trees_start Number of trees in first random forest run.
#' @param trees_add Number of trees to add in each subsequent run.
#' @param trees_max Maximum number of trees in the random forest.
#' @param rf_cores Number of cores to use for parallel processing.
#' @param use_mtry `mtry` value for `randomForest` call. If `NULL` it will be
#' generated by a (lengthy) call to `caret::train` with a tune grid of
#' `.mtry = 1:floor(sqrt(length(env_names))`
#' @param accept_prev_delta What proportion change between runs is acceptable?
#' @param accept_prev_kappa What kappa between runs is acceptable?
#' @param out_file Optional name of file to save results.
#'
#' @return
#' @export
#'
#' @examples
  make_rf_good <- function(env_df
                           , clust_col = "cluster"
                           , context = "cell"
                           , env_names
                           , trees_start = 499
                           , trees_add = 249
                           , trees_max = 9999
                           , rf_cores = 1
                           , use_mtry = NULL
                           , out_file = NULL
                           , accept_prev_delta = 0.995
                           , accept_prev_kappa = 0.995
                           ) {

    if(isTRUE(!is.null(out_file))) {

      out_file <- gsub("\\.*$","",out_file)
      out_file <- paste0(out_file,".rds")

    }

    x <- env_df[,which(names(env_df) %in% env_names)]
    y <- env_df[clust_col][[1]]

    rf_good <- list()

    # setup parallel cluster
    cl <- parallel::makePSOCKcluster(rf_cores)
    doParallel::registerDoParallel(cl)

    if(isTRUE(is.null(use_mtry))) {

      # Training control for caret implementation of machine learning methods
      ctrl <- caret::trainControl(method = "cv"
                                  , savePredictions = FALSE
                                  , verboseIter = FALSE
                                  , allowParallel = TRUE
                                  )

      # Tuning grid
      c_tune_grid <- expand.grid(.mtry = 1:floor(sqrt(length(env_names))))

      cl <- parallel::makePSOCKcluster(rf_cores)
      doParallel::registerDoParallel(cl)

      rf_good$rf_mtry <- caret::train(x
                                      , y
                                      , method = "rf"
                                      , trControl = ctrl
                                      , tuneGrid = c_tune_grid
                                      , metric = "Kappa"
                                      , trace = FALSE
                                      )

      rf_good$mtry <- rf_good$rf_mtry %>%
        `[[` ("finalModel") %>%
        `[[` ("mtry")

      } else rf_good$mtry <- use_mtry


    rf_good$rf_res <-
      tibble(run = 1
             , trees = trees_start
             , start = Sys.time()
             ) %>%
      dplyr::mutate(rf = list(make_rf_quick(x
                                            , y
                                            , trees = trees_start
                                            , cl_obj = cl
                                            , use_mtry = rf_good$mtry
                                            )
                              )
                    , seconds = Sys.time() - start
                    , metrics = purrr::map(rf
                                           , ~get_conf_metrics(y
                                                               , .$predicted
                                                               )
                                           )
                    , ntree = purrr::map_dbl(rf,"ntree")
                    ) %>%
      tidyr::unnest(cols = c(metrics)) %>%
      dplyr::mutate(prev_kappa = kap
                    , prev_delta = kap
                    )

    while(
      as.logical(
        (rf_good$rf_res$prev_kappa[[nrow(rf_good$rf_res)]] <= accept_prev_kappa) *
        (rf_good$rf_res$prev_delta[[nrow(rf_good$rf_res)]] <= accept_prev_delta) *
        (rf_good$rf_res$trees[[nrow(rf_good$rf_res)]] < trees_max)
      )
    ) {

      prev_rf <- rf_good$rf_res$rf[nrow(rf_good$rf_res)][[1]]

      start <- Sys.time()

      next_rf <- make_rf_quick(x
                                , y
                                , trees = trees_add
                                , cl_obj = cl
                                , use_mtry = rf_good$mtry
                                )

      rf_run_time <- Sys.time() - start

      new_rf <- randomForest::combine(prev_rf,next_rf)

      metrics <- get_conf_metrics(y
                                  , new_rf$predicted
                                  )

      prev_delta <- sum(prev_rf$predicted == new_rf$predicted)/length(y)

      prev_kappa <- yardstick::kap(tibble(truth = prev_rf$predicted
                                         , estimate = new_rf$predicted
                                         )
                                  , truth
                                  , estimate
                                  )$.estimate

      rf_good$rf_res <- rf_good$rf_res %>%
        dplyr::bind_rows(tibble(run = max(rf_good$rf_res$run) + 1
                                , trees = max(rf_good$rf_res$trees) + next_rf$ntree
                                , start = start
                                , rf = list(new_rf)
                                , seconds = rf_run_time
                                , prev_delta = prev_delta
                                , prev_kappa = prev_kappa
                                , ntree = new_rf$ntree
                                ) %>%
                           dplyr::bind_cols(metrics)
                         )

      cat(
        paste0("ntree: ", rf_good$rf_res$rf[[nrow(rf_good$rf_res)]]$ntree
               , "\n kappa: ",round(rf_good$rf_res$kap[[nrow(rf_good$rf_res)]],4)
               , "\n changed predictions: ",paste0(round(100-100*rf_good$rf_res$prev_delta[nrow(rf_good$rf_res)],3),"%")
               , "\n kappa based on confusion with last run: ", round(rf_good$rf_res$prev_kappa[[nrow(rf_good$rf_res)]],4)
               , "\n time: ",round(rf_good$rf_res$seconds[[nrow(rf_good$rf_res)]],2)," seconds\n\n"
        )
      )

    }

    parallel::stopCluster(cl)
    rm(cl)

    if(!isTRUE(is.null(out_file))) rio::export(rf_good,out_file)

    return(rf_good)

  }



