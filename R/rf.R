
#' Run random forest, usually returning only diagnostic values.
#'
#' Random forest is run via `caret::train`.
#'
#' @param df Dataframe with clusters, context and environmental columns.
#' @param clust_col Character. Name of column with cluster membership.
#' @param env_cols Character. Name of columns with environmental data.
#' @param trees Numeric. How many trees in the forest?
#' @param folds Numeric. How many folds to use in repeated cross-validation.
#' @param reps Numeric. How many reps to use in `rep`eated cross-validation.
#' @param tune_length Numeric. Passed to `caret::train` argument `tuneLength`.
#' @param save_rf Character. File name for saving the `train` object as (.rds).
#'
#' @return Tibble (row) of diagnostics
#'
#' @export
#'
#' @examples
  make_rf_diagnostics <- function(df
                           , clust_col = "cluster"
                           , env_cols
                           , trees = 999
                           , folds = 3
                           , reps = 5
                           , tune_length = NULL
                           , save_rf = NULL
                           ) {

    x_df <- df[,env_cols]
    y_vec <- df[clust_col][[1]]

    tune_length <- if(isTRUE(is.null(tune_length))) {

      floor(sqrt(ncol(x_df)))

    } else tune_length

    rf <- caret::train(x = x_df
                       , y = y_vec
                       , method = "rf"
                       , ntree = trees
                       , metric = "Kappa"
                       , tuneLength = tune_length
                       , trControl = caret::trainControl(method = "repeatedcv"
                                                         , number = folds
                                                         , repeats = reps
                                                         , allowParallel = FALSE
                                                         )
                       )

    if(isTRUE(!is.null(save_rf))) rio::export(rf, save_rf)

    make_kappa_tibble(rf$finalModel$confusion[,-ncol(rf$finalModel$confusion)]
          , by_class = FALSE
          )

  }


  make_rf_quick <- function(x_df
                             , y_vec
                             , trees = 499
                             , cl_obj = NULL
                             , use_mtry
                             ) {

    rf_cores <- if(isTRUE(is.null(cl_obj))) 1 else length(cl_obj)

    `%dopar%` <- foreach::`%dopar%`

    foreach::foreach(ntree = rep(ceiling(trees/rf_cores), rf_cores)
            , .combine = randomForest::combine
            , .packages = c("randomForest")
            ) %dopar%
      randomForest::randomForest(x = x_df
                                 , y = y_vec
                                 , importance = TRUE
                                 , mtry = use_mtry
                                 , ntree = ntree
                                 )

  }

#' Iteratively add trees to random forest until predictions stabilise
#'
#' @param env_df Dataframe with `clust_col`, `site_col` and columns `env_names`
#' @param clust_col Character. Name of the columns with clusters.
#' @param context Character. Name of the columns defining the context.
#' @param env_names Character. Name of the environmental variables (e.g.
#' `names(stack_list)`).
#' @param trees_start Number of trees in first random forest run.
#' @param trees_add Number of trees to add in each subsequent run.
#' @param rf_cores Number of cores to use for parallel processing.
#' @param use_mtry `mtry` value for `randomForest` call. If `NULL` it will be
#' generated by a (lengthy) call to `caret::train` with a tune grid of
#' `.mtry = 1:floor(sqrt(length(env_names))`
#' @param out_file Optional name of file to save results.
#'
#' @return
#' @export
#'
#' @examples
  make_rf_good <- function(env_df
                           , clust_col = "cluster"
                           , context = "cell"
                           , env_names
                           , trees_start = 499
                           , trees_add = 249
                           , trees_max = 9999
                           , rf_cores = 1
                           , use_mtry = NULL
                           , out_file = NULL
                           , accept_prev_delta = 0.995
                           , accept_prev_kappa = 0.995
                           ) {

    if(isTRUE(!is.null(out_file))) {

      out_file <- gsub("\\.*$","",out_file)
      out_file <- paste0(out_file,".rds")

    }

    x <- env_df[,which(names(env_df) %in% env_names)]
    y <- env_df[clust_col][[1]]

    rf_good <- list()

    # setup parallel cluster
    cl <- parallel::makePSOCKcluster(rf_cores)
    doParallel::registerDoParallel(cl)

    if(isTRUE(is.null(use_mtry))) {

      # Training control for caret implementation of machine learning methods
      ctrl <- caret::trainControl(method = "cv"
                                  , savePredictions = FALSE
                                  , verboseIter = FALSE
                                  , allowParallel = TRUE
                                  )

      # Tuning grid
      c_tune_grid <- expand.grid(.mtry = 1:floor(sqrt(length(env_names))))

      cl <- parallel::makePSOCKcluster(rf_cores)
      doParallel::registerDoParallel(cl)

      rf_good$rf_mtry <- caret::train(x
                                      , y
                                      , method = "rf"
                                      , trControl = ctrl
                                      , tuneGrid = c_tune_grid
                                      , metric = "Kappa"
                                      , trace = FALSE
                                      )

      rf_good$mtry <- rf_good$rf_mtry %>%
        `[[` ("finalModel") %>%
        `[[` ("mtry")

      } else rf_good$mtry <- use_mtry


    rf_good$rf_res <-
      tibble(run = 1
             , trees = trees_start
             , start = Sys.time()
             ) %>%
      dplyr::mutate(rf = list(make_rf_quick(x
                                             , y
                                             , trees = trees_start
                                             , cl_obj = cl
                                             , use_mtry = rf_good$mtry
                                             )
                              )
                    , seconds = Sys.time() - start
                    , conf = map(rf
                                 , ~caret::confusionMatrix(.$predicted
                                                           , y
                                                           )
                                 )
                    , kappa = map(conf
                                  , make_kappa_tibble
                                  , by_class = FALSE
                                  )
                    , ntree = map_dbl(rf,"ntree")
                    ) %>%
      tidyr::unnest(cols = c(kappa)) %>%
      dplyr::mutate(prev_kappa = kappa
                    , prev_delta = kappa
                    )

    while(
      as.logical(
        (rf_good$rf_res$prev_kappa[[nrow(rf_good$rf_res)]] <= accept_prev_kappa) *
        (rf_good$rf_res$prev_delta[[nrow(rf_good$rf_res)]] <= accept_prev_delta) *
        (rf_good$rf_res$trees[[nrow(rf_good$rf_res)]] < trees_max)
      )
    ) {

      prev_rf <- rf_good$rf_res$rf[nrow(rf_good$rf_res)][[1]]

      start <- Sys.time()

      next_rf <- make_rf_quick(x
                                , y
                                , trees = trees_add
                                , cl_obj = cl
                                , use_mtry = rf_good$mtry
                                )

      rf_run_time <- Sys.time() - start

      new_rf <- randomForest::combine(prev_rf,next_rf)

      conf <- caret::confusionMatrix(new_rf$predicted
                                      , y
                                      )

      kappa <- make_kappa_tibble(conf, by_class = FALSE)

      prev_delta <- sum(prev_rf$predicted == new_rf$predicted)/length(y)

      conf_prev <- caret::confusionMatrix(prev_rf$predicted
                                          , new_rf$predicted
                                           )

      kappa_prev <- make_kappa_tibble(conf_prev, by_class = FALSE) %>%
        stats::setNames(paste0("prev_",names(.)))

      rf_good$rf_res <- rf_good$rf_res %>%
        dplyr::bind_rows(tibble(
          run = max(rf_good$rf_res$run) + 1
          , trees = max(rf_good$rf_res$trees) + next_rf$ntree
          , start = start
          , rf = list(new_rf)
          , seconds = rf_run_time
          , conf = list(conf)
          , kappa
          , prev_delta = prev_delta
          , kappa_prev
          , ntree = new_rf$ntree
          )
          )

      cat(
        paste0("ntree: ", rf_good$rf_res$rf[[nrow(rf_good$rf_res)]]$ntree
               , "\n kappa: ",round(rf_good$rf_res$kappa[[nrow(rf_good$rf_res)]],4)
               , "\n changed predictions: ",paste0(round(100-100*rf_good$rf_res$prev_delta[nrow(rf_good$rf_res)],3),"%")
               , "\n kappa based on confusion with last run: ", round(rf_good$rf_res$prev_kappa[[nrow(rf_good$rf_res)]],4)
               , "\n time: ",round(rf_good$rf_res$seconds[[nrow(rf_good$rf_res)]],2)," seconds\n\n"
        )
      )

    }

    parallel::stopCluster(cl)
    rm(cl)

    if(!isTRUE(is.null(out_file))) rio::export(rf_good,out_file)

    return(rf_good)

  }



